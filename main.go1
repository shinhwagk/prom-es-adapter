package main

import (
	"context"
	"encoding/json"
	"log"
	"strings"

	"github.com/elastic/go-elasticsearch/esapi"
	"github.com/elastic/go-elasticsearch/v6"
	elastic "github.com/olivere/elastic/v7"
)

func main() {
	query := elastic.NewBoolQuery()
	cfg := elasticsearch.Config{
		Addresses: []string{
			"http://10.65.103.78:9200",
		},
		// ...
	}
	log.SetFlags(0)

	var (
	// r map[string]interface{}
	// wg sync.WaitGroup
	)

	// Initialize a client with the default settings.
	//
	// An `ELASTICSEARCH_URL` environment variable will be used when exported.
	//
	es, err := elasticsearch.NewClient(cfg)
	if err != nil {
		log.Fatalf("Error creating the client: %s", err)
	}

	// // 1. Get cluster info
	// //
	// res, err := es.Info()
	// if err != nil {
	// 	log.Fatalf("Error getting response: %s", err)
	// }
	// defer res.Body.Close()
	// // Check response status
	// if res.IsError() {
	// 	log.Fatalf("Error: %s", res.String())
	// }
	// // Deserialize the response into a map.
	// if err := json.NewDecoder(res.Body).Decode(&r); err != nil {
	// 	log.Fatalf("Error parsing the response body: %s", err)
	// }
	// // Print client and server version numbers.
	// log.Printf("Client: %s", elasticsearch.Version)
	// log.Printf("Server: %s", r["version"].(map[string]interface{})["number"])
	// log.Println(strings.Repeat("~", 37))

	// 2. Index documents concurrently
	//
	// for i, title := range []string{"Test One", "Test Two"} {
	// 	wg.Add(1)

	// 	go func(i int, title string) {
	// 		defer wg.Done()

	// 		// Build the request body.
	var b strings.Builder
	b.WriteString(`{"title" : "`)
	b.WriteString(`2222`)
	b.WriteString(`"}`)

	// 		// Set up the request object.
	req := esapi.IndexRequest{
		Index:   "test1",
		Body:    strings.NewReader(b.String()),
		Refresh: "true",
	}

	// 		// Perform the request with the client.
	res, err := req.Do(context.Background(), es)
	if err != nil {
		log.Fatalf("Error getting response: %s", err)
	}
	defer res.Body.Close()

	if res.IsError() {
		log.Printf("[%s] Error indexing document ID=%d", res.Status(), 1)
	} else {
		// Deserialize the response into a map.
		var r map[string]interface{}
		if err := json.NewDecoder(res.Body).Decode(&r); err != nil {
			log.Printf("Error parsing the response body: %s", err)
		} else {
			// Print the response status and indexed document version.
			log.Printf("[%s] %s; version=%d", res.Status(), r["result"], int(r["_version"].(float64)))
		}
	}

	// 	}(i, title)
	// }
	// wg.Wait()

	// log.Println(strings.Repeat("-", 37))

	// // 3. Search for the indexed documents
	// //
	// // Build the request body.
	// var buf bytes.Buffer

	// query := map[string]interface{}{
	// 	"query": map[string]interface{}{
	// 		"bool": map[string]interface{}{
	// 			"must": []map[string]interface{}{ //"must_not"
	// 				{
	// 					"match_phrase": map[string]interface{}{
	// 						"label.__name__": map[string]interface{}{
	// 							"query": "prometheus_tsdb_compaction_duration_seconds_bucket",
	// 						},
	// 					},
	// 				},
	// 				{
	// 					"range": map[string]interface{}{
	// 						"timestamp": map[string]interface{}{
	// 							"gte":    1589869717731,
	// 							"lte":    1589884117731,
	// 							"format": "epoch_millis",
	// 						},
	// 					},
	// 				},
	// 			},
	// 		},
	// 	},
	// }

	// if err := json.NewEncoder(&buf).Encode(query); err != nil {
	// 	log.Fatalf("Error encoding query: %s", err)
	// }
	// fmt.Println(buf.String())
	// // Perform the search request.
	// res, err = es.Search(
	// 	es.Search.WithContext(context.Background()),
	// 	es.Search.WithIndex("prom-metrics-1"),
	// 	es.Search.WithBody(&buf),
	// 	es.Search.WithTrackTotalHits(true),
	// 	es.Search.WithPretty(),
	// )
	// if err != nil {
	// 	log.Fatalf("Error getting response: %s", err)
	// }
	// defer res.Body.Close()

	// if res.IsError() {
	// 	var e map[string]interface{}
	// 	if err := json.NewDecoder(res.Body).Decode(&e); err != nil {
	// 		log.Fatalf("Error parsing the response body: %s", err)
	// 	} else {
	// 		// Print the response status and error information.
	// 		log.Fatalf("[%s] %s: %s",
	// 			res.Status(),
	// 			e["error"].(map[string]interface{})["type"],
	// 			e["error"].(map[string]interface{})["reason"],
	// 		)
	// 	}
	// }

	// if err := json.NewDecoder(res.Body).Decode(&r); err != nil {
	// 	log.Fatalf("Error parsing the response body: %s", err)
	// }
	// // Print the response status, number of results, and request duration.

	// resultByte, _ := json.Marshal(r)
	// fmt.Println(string(resultByte))
	// fmt.Println(r["took"])
	// log.Printf(
	// 	"[%s]  hits; took: %s ms",
	// 	res.Status(),
	// 	// int(r["hits"].(map[string]interface{})["total"].(map[string]interface{})["value"].(float64)),
	// 	r["name"].(string),
	// )
	// Print the ID and document source for each hit.
	// for _, hit := range r["hits"].(map[string]interface{})["hits"].([]interface{}) {
	// 	log.Printf(" * ID=%s, %s", hit.(map[string]interface{})["_id"], hit.(map[string]interface{})["_source"])
	// }

	// log.Println(strings.Repeat("=", 37))
}
